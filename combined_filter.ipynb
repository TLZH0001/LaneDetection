{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55ebe7898a80] Referenced QT chapter track not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import imutils\n",
    "cap = cv2.VideoCapture(\"/home/roar/Desktop/LaneDetection/training_1000.MOV\")\n",
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floodfilled(frame):\n",
    "    img = frame.copy()\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    img_hsv = cv2.GaussianBlur(img_hsv, (5,5), 0)\n",
    "\n",
    "    #frame = imutils.resize(frame,width = 960)\n",
    "    seed = (1079, 920)\n",
    "\n",
    "    box = (200, 200)\n",
    "    x = (seed[0] - box[0] - box[1], seed[0])\n",
    "    y = (seed[1] - box[1], seed[1] + box[1])\n",
    "\n",
    "\n",
    "    mean = np.mean(img_hsv[x[0]:x[1], y[0]:y[1], :], axis = (0,1))\n",
    "    # std = np.std(frame[x[0]:x[1], y[0]:y[1], :], axis = (0,1))\n",
    "    # scale = 2.5\n",
    "    # scale_std = std * scale\n",
    "    # scale_std[2] = 200\n",
    "    # scale_std[1] = 50\n",
    "    # print(scale_std)\n",
    "    # break\n",
    "    scale_std = [50, 50, 200]\n",
    "    # print(mean, '/n',std)\n",
    "\n",
    "    img_hsv[seed[0], seed[1]] = mean\n",
    "\n",
    "    #crop_frame = frame[200:]\n",
    "    #print(crop_frame.shape)\n",
    "\n",
    "    \n",
    "    mask = np.zeros((img_hsv.shape[0] + 2, img_hsv.shape[1] + 2)).astype(np.uint8)\n",
    "    cv2.floodFill(img_hsv, mask, seedPoint=seed, newVal=(255, 0, 0), \\\n",
    "        loDiff=tuple(scale_std), upDiff=tuple(scale_std), flags= cv2.FLOODFILL_FIXED_RANGE)\n",
    "    cv2.circle(img_hsv, seed, 2, (0, 255, 0), cv2.FILLED, cv2.LINE_AA)\n",
    "    mask = mask * 255\n",
    "    return img_hsv, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grass_detection(frame, remove_niose : bool = False):\n",
    "    \n",
    "    img = frame.copy()\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    kernel_size = 5\n",
    "    blur = cv2.GaussianBlur(img_hsv, (5,5), 0)\n",
    "    \n",
    "    low_green = np.array([25, 52, 72])\n",
    "    high_green = np.array([200, 200, 255])\n",
    "\n",
    "    filter_size = (150, img_hsv.shape[1])\n",
    "    sky_filter = np.zeros(filter_size)\n",
    "\n",
    "    flt = cv2.inRange(blur[150:], low_green, high_green)\n",
    "    combo_filter = np.concatenate((sky_filter, flt), axis = 0)\n",
    "    kernel = np.ones((kernel_size*2,kernel_size*2),np.uint8)\n",
    "    dilation_filter = cv2.dilate(combo_filter, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(combo_filter, cv2.MORPH_OPEN, None).astype(np.uint8)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_road_detection(frame):\n",
    "\n",
    "    img = frame.copy()\n",
    "    \n",
    "    lower_road = np.array([117, 0, 98])\n",
    "    upper_road = np.array([179, 20, 204])\n",
    "    \n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # Threshold the HSV image to get only road colors\n",
    "    mask = cv2.inRange(hsv_img, lower_road, upper_road)\n",
    "\n",
    "    mask = cv2.erode(mask, np.ones((3, 3), np.uint8))\n",
    "    mask = cv2.dilate(mask, np.ones((5, 5), np.uint8))\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_MASK_LOWER = np.array([0,0,80],dtype='uint8')\n",
    "GROUND_MASK_UPPER = np.array([255,50,200],dtype='uint8')\n",
    "GRASS_MASK_LOWER = np.array([43,50,20],dtype='uint8')\n",
    "GRASS_MASK_UPPER = np.array([128,255,255],dtype='uint8')\n",
    "\n",
    "dilkernel = np.ones((5,5), np.uint8)\n",
    "erokernel = np.ones((6,6), np.uint8)\n",
    "erokernel[:2,:] = 0\n",
    "erokernel[-2:,:] = 0\n",
    "erokernel[:,:2]=0\n",
    "erokernel[:,-2:]=0\n",
    "\n",
    "def groundAndGrassMask(image):\n",
    "    hsvImg = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    ground = cv2.inRange(hsvImg,GROUND_MASK_LOWER,GROUND_MASK_UPPER)\n",
    "    grass = cv2.inRange(hsvImg,GRASS_MASK_LOWER,GRASS_MASK_UPPER)\n",
    "    \n",
    "    grass = cv2.erode(grass,erokernel,iterations=2)\n",
    "    ground = cv2.erode(ground,erokernel,iterations=2)\n",
    "    ground = cv2.dilate(ground,dilkernel,iterations=10)\n",
    "    grass = cv2.dilate(grass, dilkernel, iterations=10)\n",
    "    \n",
    "    combined = cv2.bitwise_and(ground,cv2.bitwise_not(grass))\n",
    "    combined = cv2.erode(combined,erokernel,iterations=4)\n",
    "    #combined = cv.dilate(combined,dilkernel,iterations=5)\n",
    "    \n",
    "    return ground,grass,combined\n",
    "\n",
    "def getContour(alpha):\n",
    "    #https://stackoverflow.com/questions/66753026/opencv-smoother-contour\n",
    "    contours,hierachy = cv2.findContours(alpha,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    big_contour = max(contours, key=cv2.contourArea)\n",
    "    contour_img = np.zeros_like(alpha)\n",
    "    cv2.drawContours(contour_img, [big_contour], 0, 255, -1)\n",
    "    # apply dilate to connect the white areas in the alpha channel\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (40,40))\n",
    "    dilate = cv2.morphologyEx(contour_img, cv2.MORPH_DILATE, kernel)\n",
    "    return dilate, None\n",
    "\n",
    "def road_and_grass_detection(frame):\n",
    "    img = frame.copy()\n",
    "    ground, grass, comb = groundAndGrassMask(img)\n",
    "    dilatedContour, edge = getContour(comb)\n",
    "    return dilatedContour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_mask(mask):\n",
    "    mask_copy = mask.copy()\n",
    "    gx, gy = np.gradient(mask_copy)\n",
    "    temp_edge = gy * gy + gx * gx\n",
    "    temp_edge[temp_edge != 0.0] = 255.0\n",
    "    temp_edge = temp_edge.astype(np.uint8)\n",
    "\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(temp_edge, connectivity=8)\n",
    "    sizes = stats[1:, -1]\n",
    "    nb_components = nb_components - 1\n",
    "    min_size = 1000  #num pixels\n",
    "\n",
    "    img2 = np.zeros((output.shape))\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= min_size:\n",
    "            img2[output == i + 1] = 255\n",
    "\n",
    "    return img2\n",
    "\n",
    "def closest_edge(mask_of_edge):\n",
    "    final_mask = np.zeros_like(mask_of_edge)\n",
    "    for j in range(mask_of_edge.shape[1]):\n",
    "        # ys = np.where(img2[:, j] !=0 )\n",
    "        # print(ys)\n",
    "        # if ys:\n",
    "        #     print(\"empty\")\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     print(\"not empty\")\n",
    "        #     i = np.max(ys)\n",
    "        #     img3 = [i][j] = 255\n",
    "        for i in reversed(range(mask_of_edge.shape[0])):\n",
    "            if mask_of_edge[i][j] != 0:\n",
    "                final_mask[i][j] = 255\n",
    "                break\n",
    "    return final_mask\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES_PER_TIME = 20\n",
    "frameCount = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    frameCount += NUM_FRAMES_PER_TIME # i.e. at 30 fps, this advances one second\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frameCount)\n",
    "\n",
    "    # cv2.namedWindow(\"original\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow(\"floodfilled road\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow(\"floodfilled mask\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow(\"grass detection mask\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow(\"road detection mask\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow(\"road & grass detection mask\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow('and mask', cv2.WINDOW_KEEPRATIO)\n",
    "\n",
    "    # cv2.namedWindow(\"floodfilled lane\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow(\"grass detection lane\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow(\"road detection lane\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow(\"road & grass detection lane\", cv2.WINDOW_KEEPRATIO)\n",
    "    # cv2.namedWindow('and lane', cv2.WINDOW_KEEPRATIO)\n",
    "\n",
    "\n",
    "    # floodfilled_road, floodfilled_mask = floodfilled(frame)\n",
    "    grass_detection_mask = grass_detection(frame)\n",
    "    road_detection_mask = hsv_road_detection(frame)\n",
    "    # rg_detection_mask = road_and_grass_detection(frame)\n",
    "    and_mask = np.bitwise_and(road_detection_mask, np.bitwise_not(grass_detection_mask))\n",
    "\n",
    "    # floodfilled_edge = edge_mask(floodfilled_mask)\n",
    "    grass_edge = edge_mask(grass_detection_mask)\n",
    "    road_edge = edge_mask(road_detection_mask)\n",
    "    # rg_edge = edge_mask(rg_detection_mask)\n",
    "    and_edge = edge_mask(and_mask)\n",
    "\n",
    "    # cv2.imshow('original', frame)\n",
    "    # cv2.imshow('floodfilled road', floodfilled_road)\n",
    "    # cv2.imshow('floodfilled mask', floodfilled_mask)\n",
    "    cv2.imshow('grass detection mask', grass_detection_mask)\n",
    "    cv2.imshow('road detection mask', road_detection_mask)\n",
    "    # cv2.imshow('road & grass detection mask', rg_detection_mask)\n",
    "    cv2.imshow('and mask', and_mask)\n",
    "\n",
    "    # cv2.imshow('floodfilled lane', floodfilled_edge)\n",
    "    # cv2.imshow('grass detection lane', grass_edge)\n",
    "    # cv2.imshow('road detection lane', road_edge)\n",
    "    # cv2.imshow('road & grass detection lane', rg_edge)\n",
    "    cv2.imshow('and lane', and_edge)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9a9c7f2737dedd0b37988c9f92d29557e26ebc3804ba18c5cbd2b7762b1fc4e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ROAR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
